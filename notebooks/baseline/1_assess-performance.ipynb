{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assess Search\n",
    "Get some statistics from brute-forcing the search, such as the expected performance of random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import sem\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file = 'E15.csv.gz'  # Where to read from\n",
    "perc = np.array([99, 99.9, 99.99, 99.999, 99.9999])  # Which percentiles to compute\n",
    "search_size = 1000000  # How many molecules to same in random search\n",
    "n_tests = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in Results\n",
    "They are produced in an earlier notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 15547091 entries\n",
      "CPU times: user 33.9 s, sys: 2.11 s, total: 36 s\n",
      "Wall time: 36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = pd.read_csv(result_file)  # Remember to uncomment end later\n",
    "print(f'Loaded {len(data)} entries')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop rows with missing IC50's, which occur if the molecule is not fully connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed nulls. New size 15538418\n"
     ]
    }
   ],
   "source": [
    "data = data[~data.pIC50_mpnn.isnull()]\n",
    "print(f'Removed nulls. New size {len(data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Top Percentiles\n",
    "How good are the best molecules?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r, is_max in zip(['pIC50_mpnn', 'logP'], [True, False]):\n",
    "    my_perc = perc if is_max else 100 - perc\n",
    "    values = np.percentile(data[r], my_perc)\n",
    "\n",
    "    with open(f'top_{r}.json', 'w') as fp:\n",
    "        json.dump({\n",
    "            'percentiles': my_perc.tolist(),\n",
    "            r: values.tolist(),\n",
    "            'best': data[r].max() if is_max else data[r].min(),\n",
    "            'maximize': is_max\n",
    "        }, fp, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate a Random Search\n",
    "Simulate a random search by drawing compounds at random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_random_search(reward: str, n_tests: int, threshold: float, maximize: bool):\n",
    "    # Run the tests\n",
    "    cum_best = []\n",
    "    past_thresh = []\n",
    "    for _ in tqdm(range(n_tests)):\n",
    "        choices = data.sample(search_size)\n",
    "        cum_best.append(choices[reward].cummax() if maximize else choices[reward].cummin())\n",
    "        t = choices[reward] > threshold if maximize else choices[reward] < threshold\n",
    "        past_thresh.append(np.cumsum(t))\n",
    "    cum_best = np.vstack(cum_best)\n",
    "    past_tresh = np.vstack(past_thresh)\n",
    "\n",
    "    # Save the mean and standard error for the cumulative min\n",
    "    best_sem = sem(cum_best, axis=0)\n",
    "    best_mean = np.mean(cum_best, axis=0)\n",
    "    thresh_sem = sem(past_thresh, axis=0)\n",
    "    thresh_mean = np.mean(past_thresh, axis=0)\n",
    "\n",
    "    # WRite out the data file\n",
    "    pd.DataFrame({\n",
    "        'best_mean': best_mean,\n",
    "        'best_sem': best_sem,\n",
    "        'past_thresh_mean': thresh_mean,\n",
    "        'past_thresh_sem': thresh_sem\n",
    "    }).to_csv(f'random_search_perf_{reward}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [01:15<00:00,  1.17s/it]\n",
      "100%|██████████| 64/64 [01:14<00:00,  1.16s/it]\n"
     ]
    }
   ],
   "source": [
    "for r, t, m in zip(['pIC50_mpnn', 'logP'], [8, 5], [True, False]):\n",
    "    simulate_random_search(r, n_tests=n_tests, threshold=t, maximize=m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
