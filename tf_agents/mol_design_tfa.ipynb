{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0-dev20200802\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import base64\n",
    "import imageio\n",
    "import IPython\n",
    "import json\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL.Image\n",
    "import random\n",
    "# import pyvirtualdisplay\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.drivers import dynamic_step_driver\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.environments import py_environment\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.environments import tf_environment\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.environments import utils\n",
    "from tf_agents.environments import wrappers\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.networks import q_network\n",
    "from tf_agents.policies import random_tf_policy\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.specs import array_spec\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "from tf_agents.utils import common\n",
    "\n",
    "from molgym.agents.preprocessing import MorganFingerprints\n",
    "from molgym.envs.rewards import RewardFunction\n",
    "from molgym.envs.rewards.multiobjective import AdditiveReward\n",
    "from molgym.envs.rewards.oneshot import OneShotScore\n",
    "from molgym.envs.rewards.tuned import LogisticCombination\n",
    "from molgym.envs.rewards.rdkit import LogP, QEDReward, SAScore, CycleLength\n",
    "from molgym.envs.rewards.mpnn import MPNNReward\n",
    "from rdkit.Chem import GetPeriodicTable, MolFromSmiles\n",
    "from molgym.mpnn.layers import custom_objects\n",
    "from molgym.utils.conversions import convert_nx_to_smiles, convert_rdkit_to_nx, convert_smiles_to_nx\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "tf.compat.v1.enable_v2_behavior()\n",
    "print(tf.version.VERSION)\n",
    "\n",
    "num_iterations = 20000 # @param {type:\"integer\"}\n",
    "\n",
    "initial_collect_steps = 1000  # @param {type:\"integer\"} \n",
    "collect_steps_per_iteration = 1  # @param {type:\"integer\"}\n",
    "replay_buffer_max_length = 100000  # @param {type:\"integer\"}\n",
    "\n",
    "batch_size = 64  # @param {type:\"integer\"}\n",
    "learning_rate = 1e-3  # @param {type:\"number\"}\n",
    "log_interval = 200  # @param {type:\"integer\"}\n",
    "\n",
    "num_eval_episodes = 10  # @param {type:\"integer\"}\n",
    "eval_interval = 1000  # @param {type:\"integer\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from molgym.agents.preprocessing import MorganFingerprints\n",
    "# from molgym.utils.conversions import convert_rdkit_to_nx\n",
    "# from molgym.envs.actions.utils import get_valid_actions\n",
    "# emb_sz = 64 \n",
    "# processor =  MorganFingerprints(emb_sz)\n",
    "# from rdkit import Chem\n",
    "# # m = Chem.MolFromSmiles('CCC(CC)COC(=O)C(C)NP(=O)(OCC1C(C(C(O1)(C#N)C2=CC=C3N2N=CN=C3N)O)O)OC4=CC=CC=C4')\n",
    "# m = Chem.MolFromSmiles('C#C')\n",
    "\n",
    "# graph = convert_rdkit_to_nx(m)\n",
    "# print(list(graph.nodes(data=True)))\n",
    "# valid_actions = get_valid_actions('C#C', set(['C', 'O', 'N', 'F']), False, False, None, True, None)\n",
    "# print(np.random.choice(5))\n",
    "# # embedding = processor.get_features([graph])\n",
    "# # print(embedding[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MolecularGraphEncoder:\n",
    "    def __init__(self, opt='mf', emb_sz=64):\n",
    "        self.opt = opt \n",
    "        self.processor =  MorganFingerprints(emb_sz)\n",
    "        return\n",
    "    \n",
    "    def encode(self, smiles_str):\n",
    "        graph = convert_smiles_to_nx(smiles_str)\n",
    "        if self.opt == 'mf': # Morgan fingerprint\n",
    "            embedding = self.processor.get_features([graph])\n",
    "            return embedding[0]\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "class MolDesignEnv(py_environment.PyEnvironment):\n",
    "    def __init__(self):\n",
    "        self.action_space = ['C', 'O', 'N', 'F'] # or it can be a functional group as well\n",
    "        self.emb_dims = 128\n",
    "        self.MAX_ATOM_COUNT = 64\n",
    "        self.MAX_BOND_COUNT = 100\n",
    "        self.graph_encoder = MolecularGraphEncoder()\n",
    "        self.init_reward_func()\n",
    "\n",
    "        # Action is a 4-tuple (src_node_idx, relation_type, dst_node_idx, dst_node_type)\n",
    "        self._action_spec = array_spec.BoundedArraySpec(\n",
    "            shape=(1, 4), dtype=np.int32, minimum=0, maximum=self.MAX_ATOM_COUNT-1, name='action')\n",
    "        self._observation_spec = array_spec.BoundedArraySpec(\n",
    "            shape=(1,), dtype=np.float32, minimum=0, name='observation')\n",
    "\n",
    "    #     m = Chem.MolFromSmiles('C')\n",
    "        self._state = 'C' #convert_rdkit_to_nx(m)\n",
    "        self._episode_ended = False\n",
    "    \n",
    "    def init_reward_func(self):\n",
    "        # Get the list of elements\n",
    "        #  We want those where SMILES supports implicit valences\n",
    "        mpnn_dir = os.path.join('../notebooks', 'mpnn-training')\n",
    "        with open(os.path.join(mpnn_dir, 'atom_types.json')) as fp:\n",
    "            atom_types = json.load(fp)\n",
    "        with open(os.path.join(mpnn_dir, 'bond_types.json')) as fp:\n",
    "            bond_types = json.load(fp)\n",
    "        pt = GetPeriodicTable()\n",
    "        elements = [pt.GetElementSymbol(i) for i in atom_types]\n",
    "        elements = [e for e in elements if MolFromSmiles(e) is not None]\n",
    "\n",
    "        # Prepare the one-shot model. We the molecules to compare against and the comparison model\n",
    "        with open(os.path.join('../seed-molecules', 'top_100_pIC50.json')) as fp:\n",
    "            comparison_mols = [convert_smiles_to_nx(s) for s in json.load(fp)]\n",
    "        oneshot_dir = '../similarity'\n",
    "        oneshot_model = load_model(os.path.join(oneshot_dir, 'oneshot_model.h5'), custom_objects=custom_objects)\n",
    "        with open(os.path.join(oneshot_dir, 'atom_types.json')) as fp:\n",
    "            os_atom_types = json.load(fp)\n",
    "        with open(os.path.join(oneshot_dir, 'bond_types.json')) as fp:\n",
    "            os_bond_types = json.load(fp)\n",
    "\n",
    "        # Making all of the reward functions\n",
    "        # model = load_model(os.path.join(mpnn_dir, 'best_model.h5'), custom_objects=custom_objects)\n",
    "\n",
    "        rewards = {\n",
    "                'logP': LogP(maximize=True),\n",
    "        #         'ic50': MPNNReward(model, atom_types, bond_types, maximize=True),\n",
    "                'QED': QEDReward(maximize=True),\n",
    "                'SA': SAScore(maximize=False),\n",
    "                'cycles': CycleLength(maximize=False),\n",
    "                'oneshot': OneShotScore(oneshot_model, os_atom_types, os_bond_types, comparison_mols, maximize=True)\n",
    "            }\n",
    "\n",
    "        # Load in the ranges for reward functions, used in making multi-objective searches\n",
    "        with open('reward_ranges.json') as fp:\n",
    "            ranges = json.load(fp)\n",
    "\n",
    "        opt_reward = 'QED'\n",
    "        # Make the reward function\n",
    "        if opt_reward == 'ic50':\n",
    "            self.reward_func = rewards['ic50']\n",
    "        elif opt_reward == 'logP':\n",
    "            self.reward_func = AdditiveReward([{'reward': rewards[r], **ranges[r]} for r in ['logP', 'SA', 'cycles']])\n",
    "        elif opt_reward == \"QED\":\n",
    "            self.reward_func = AdditiveReward([{'reward': rewards[r], **ranges[r]} for r in ['QED', 'SA', 'cycles']])\n",
    "        elif opt_reward == \"MO\":\n",
    "            self.reward_func = AdditiveReward([{'reward': rewards[r], **ranges[r]} for r in ['ic50', 'QED', 'SA', 'cycles']])\n",
    "        elif opt_reward == \"oneshot\":\n",
    "            self.reward_func = rewards['oneshot']\n",
    "        elif opt_reward == \"tuned\":\n",
    "            self.reward_func = LogisticCombination(rewards['ic50'], rewards['oneshot'])\n",
    "        else:\n",
    "            raise ValueError(f'Reward function not defined: {args.reward}')\n",
    "        return\n",
    "\n",
    "    def action_spec(self):\n",
    "        return self._action_spec\n",
    "\n",
    "    def observation_spec(self):\n",
    "        return self._observation_spec\n",
    "\n",
    "    def _reset(self):\n",
    "        self._state = 'C'\n",
    "        self._episode_ended = False\n",
    "        return ts.restart(self.graph_encoder.encode(self._state))\n",
    "\n",
    "    def _step(self, action):\n",
    "\n",
    "        if self._episode_ended:\n",
    "            # The last action ended the episode. Ignore the current action and start\n",
    "            # a new episode.\n",
    "            return self.reset()\n",
    "\n",
    "        mol = Chem.MolFromSmiles(self._state)\n",
    "        graph = convert_rdkit_to_nx(mol)\n",
    "        \n",
    "        # This can change if we are dealing with a coarsened graph and nodes \n",
    "        # represent functional groups and NOT atoms\n",
    "        atom_count = graph.number_of_nodes() \n",
    "        num_bonds = graph.number_of_edges()\n",
    "        # Make sure episodes don't go on forever.\n",
    "        if atom_count == self.MAX_ATOM_COUNT or num_bonds == self.MAX_BOND_COUNT:\n",
    "            self._episode_ended = True\n",
    "        else:\n",
    "            valid_actions = get_valid_actions(self._state, set(['C', 'O', 'N', 'F']), False, False, None, True, None)\n",
    "            if len(valid_actions) == 0:\n",
    "                self._episode_ended = True\n",
    "            else:  \n",
    "                self._state = random.sample(valid_actions, 1)[0]\n",
    "\n",
    "        reward = self.reward_func(graph)\n",
    "        if self._episode_ended:\n",
    "            return ts.termination(self.graph_encoder.encode(self._state), reward)\n",
    "        else:\n",
    "            return ts.transition(self.graph_encoder.encode(self._state), reward=0.0, discount=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the list of elements\n",
    "# #  We want those where SMILES supports implicit valences\n",
    "# mpnn_dir = os.path.join('../notebooks', 'mpnn-training')\n",
    "# with open(os.path.join(mpnn_dir, 'atom_types.json')) as fp:\n",
    "#     atom_types = json.load(fp)\n",
    "# with open(os.path.join(mpnn_dir, 'bond_types.json')) as fp:\n",
    "#     bond_types = json.load(fp)\n",
    "# pt = GetPeriodicTable()\n",
    "# elements = [pt.GetElementSymbol(i) for i in atom_types]\n",
    "# elements = [e for e in elements if MolFromSmiles(e) is not None]\n",
    "\n",
    "# # Prepare the one-shot model. We the molecules to compare against and the comparison model\n",
    "# with open(os.path.join('../seed-molecules', 'top_100_pIC50.json')) as fp:\n",
    "#     comparison_mols = [convert_smiles_to_nx(s) for s in json.load(fp)]\n",
    "# oneshot_dir = '../similarity'\n",
    "# oneshot_model = load_model(os.path.join(oneshot_dir, 'oneshot_model.h5'), custom_objects=custom_objects)\n",
    "# with open(os.path.join(oneshot_dir, 'atom_types.json')) as fp:\n",
    "#     os_atom_types = json.load(fp)\n",
    "# with open(os.path.join(oneshot_dir, 'bond_types.json')) as fp:\n",
    "#     os_bond_types = json.load(fp)\n",
    "        \n",
    "# # Making all of the reward functions\n",
    "# # model = load_model(os.path.join(mpnn_dir, 'best_model.h5'), custom_objects=custom_objects)\n",
    "\n",
    "# rewards = {\n",
    "#         'logP': LogP(maximize=True),\n",
    "# #         'ic50': MPNNReward(model, atom_types, bond_types, maximize=True),\n",
    "#         'QED': QEDReward(maximize=True),\n",
    "#         'SA': SAScore(maximize=False),\n",
    "#         'cycles': CycleLength(maximize=False),\n",
    "#         'oneshot': OneShotScore(oneshot_model, os_atom_types, os_bond_types, comparison_mols, maximize=True)\n",
    "#     }\n",
    "\n",
    "# # Load in the ranges for reward functions, used in making multi-objective searches\n",
    "# with open('reward_ranges.json') as fp:\n",
    "#     ranges = json.load(fp)\n",
    "\n",
    "# opt_reward = 'QED'\n",
    "# # Make the reward function\n",
    "# if opt_reward == 'ic50':\n",
    "#     reward = rewards['ic50']\n",
    "# elif opt_reward == 'logP':\n",
    "#     reward = AdditiveReward([{'reward': rewards[r], **ranges[r]} for r in ['logP', 'SA', 'cycles']])\n",
    "# elif opt_reward == \"QED\":\n",
    "#     reward = AdditiveReward([{'reward': rewards[r], **ranges[r]} for r in ['QED', 'SA', 'cycles']])\n",
    "# elif opt_reward == \"MO\":\n",
    "#     reward = AdditiveReward([{'reward': rewards[r], **ranges[r]} for r in ['ic50', 'QED', 'SA', 'cycles']])\n",
    "# elif opt_reward == \"oneshot\":\n",
    "#     reward = rewards['oneshot']\n",
    "# elif opt_reward == \"tuned\":\n",
    "#     reward = LogisticCombination(rewards['ic50'], rewards['oneshot'])\n",
    "# else:\n",
    "#     raise ValueError(f'Reward function not defined: {args.reward}')\n",
    "    \n",
    "# print(reward(graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [03:33:47] SMILES Parse Error: syntax error while parsing: Si\n",
      "RDKit ERROR: [03:33:47] SMILES Parse Error: Failed parsing SMILES 'Si' for input: 'Si'\n",
      "RDKit ERROR: [03:33:47] SMILES Parse Error: syntax error while parsing: Mn\n",
      "RDKit ERROR: [03:33:47] SMILES Parse Error: Failed parsing SMILES 'Mn' for input: 'Mn'\n",
      "RDKit ERROR: [03:33:47] non-ring atom 1 marked aromatic\n",
      "RDKit ERROR: [03:33:47] SMILES Parse Error: syntax error while parsing: Cu\n",
      "RDKit ERROR: [03:33:47] SMILES Parse Error: Failed parsing SMILES 'Cu' for input: 'Cu'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of steps: 12\n"
     ]
    }
   ],
   "source": [
    "environment = MolDesignEnv()\n",
    "action = np.array(1, dtype=np.int32)\n",
    "time_step = environment.reset()\n",
    "# print(time_step)\n",
    "num_time_steps = 0\n",
    "while not time_step.is_last():\n",
    "    time_step = environment.step(action)\n",
    "    num_time_steps += 1\n",
    "print('Number of steps: %d' % num_time_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [04:02:32] SMILES Parse Error: syntax error while parsing: Si\n",
      "RDKit ERROR: [04:02:32] SMILES Parse Error: Failed parsing SMILES 'Si' for input: 'Si'\n",
      "RDKit ERROR: [04:02:32] SMILES Parse Error: syntax error while parsing: Mn\n",
      "RDKit ERROR: [04:02:32] SMILES Parse Error: Failed parsing SMILES 'Mn' for input: 'Mn'\n",
      "RDKit ERROR: [04:02:32] non-ring atom 1 marked aromatic\n",
      "RDKit ERROR: [04:02:32] SMILES Parse Error: syntax error while parsing: Cu\n",
      "RDKit ERROR: [04:02:32] SMILES Parse Error: Failed parsing SMILES 'Cu' for input: 'Cu'\n",
      "RDKit ERROR: [04:02:33] SMILES Parse Error: syntax error while parsing: Si\n",
      "RDKit ERROR: [04:02:33] SMILES Parse Error: Failed parsing SMILES 'Si' for input: 'Si'\n",
      "RDKit ERROR: [04:02:33] SMILES Parse Error: syntax error while parsing: Mn\n",
      "RDKit ERROR: [04:02:33] SMILES Parse Error: Failed parsing SMILES 'Mn' for input: 'Mn'\n",
      "RDKit ERROR: [04:02:33] non-ring atom 1 marked aromatic\n",
      "RDKit ERROR: [04:02:33] SMILES Parse Error: syntax error while parsing: Cu\n",
      "RDKit ERROR: [04:02:33] SMILES Parse Error: Failed parsing SMILES 'Cu' for input: 'Cu'\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Network only supports action_specs with shape in [(), (1,)])\n  In call to configurable 'QNetwork' (<class 'tf_agents.networks.q_network.QNetwork'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-8a368c5d52b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtrain_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtrain_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     fc_layer_params=fc_layer_params)\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/gin/config.py\u001b[0m in \u001b[0;36mgin_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1076\u001b[0m       \u001b[0mscope_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" in scope '{}'\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscope_str\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mscope_str\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m       \u001b[0merr_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merr_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn_or_cls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1078\u001b[0;31m       \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugment_exception_message_and_reraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1079\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mgin_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/gin/utils.py\u001b[0m in \u001b[0;36maugment_exception_message_and_reraise\u001b[0;34m(exception, message)\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPY3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mExceptionProxy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__qualname__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__qualname__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproxy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproxy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/gin/config.py\u001b[0m in \u001b[0;36mgin_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1055\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1056\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m       \u001b[0merr_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tf_agents/networks/network.py\u001b[0m in \u001b[0;36m_capture_init\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_inspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcallargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"self\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m       \u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m       \u001b[0;31m# Avoid auto tracking which prevents keras from tracking layers that are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0;31m# passed as kwargs to the Network.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tf_agents/networks/q_network.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_tensor_spec, action_spec, preprocessing_layers, preprocessing_combiner, conv_layer_params, fc_layer_params, dropout_layer_params, activation_fn, kernel_initializer, batch_squash, dtype, name)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0maction_spec\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mcontains\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \"\"\"\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0mvalidate_specs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0maction_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0mnum_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0maction_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimum\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tf_agents/networks/q_network.py\u001b[0m in \u001b[0;36mvalidate_specs\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mflat_action_spec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     raise ValueError(\n\u001b[0;32m---> 39\u001b[0;31m         'Network only supports action_specs with shape in [(), (1,)])')\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Network only supports action_specs with shape in [(), (1,)])\n  In call to configurable 'QNetwork' (<class 'tf_agents.networks.q_network.QNetwork'>)"
     ]
    }
   ],
   "source": [
    "train_env = tf_py_environment.TFPyEnvironment(MolDesignEnv())\n",
    "eval_env = tf_py_environment.TFPyEnvironment(MolDesignEnv())\n",
    "\n",
    "fc_layer_params = (100,)\n",
    "\n",
    "q_net = q_network.QNetwork(\n",
    "    train_env.observation_spec(),\n",
    "    train_env.action_spec(),\n",
    "    fc_layer_params=fc_layer_params)\n",
    "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "train_step_counter = tf.Variable(0)\n",
    "\n",
    "agent = dqn_agent.DqnAgent(\n",
    "    train_env.time_step_spec(),\n",
    "    train_env.action_spec(),\n",
    "    q_network=q_net,\n",
    "    optimizer=optimizer,\n",
    "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
    "    train_step_counter=train_step_counter)\n",
    "\n",
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
